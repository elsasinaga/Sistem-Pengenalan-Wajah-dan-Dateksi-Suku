{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistem Deteksi Wajah dan Suku/Etnis\n",
    "\n",
    "Notebook ini menunjukkan:\n",
    "1. **Deteksi Wajah**: Menggunakan MTCNN untuk mendeteksi wajah.\n",
    "2. **Face Similarity**: Menggunakan model Siamese (ResNet50) untuk menghitung *Euclidean distance* antar wajah.\n",
    "3. **Deteksi Suku/Etnis**: Menggunakan model MobileNetV2 untuk memprediksi suku/etnis.\n",
    "4. **Evaluasi**: Metrik untuk *face similarity* (precision, recall, F1, TAR, FAR, FRR) dan deteksi suku/etnis (classification report, confusion matrix).\n",
    "5. **Visualisasi**: ROC curve, distribusi jarak, t-SNE, confusion matrix, dan contoh inferensi.\n",
    "\n",
    "**Prasyarat**:\n",
    "- Dataset: `training.csv`, `validation.csv`, `testing.csv` dengan kolom `path`, `nama`, `suku`, `ekspresi`, `sudut`, `jarak`, `pencahayaan`.\n",
    "- Model: `feature_extractor_siamese.h5` (face similarity), `ethnicity_model.h5` (deteksi suku/etnis), `label_encoder.pkl` (LabelEncoder).\n",
    "- Gambar: Disimpan di `training/[suku]/[nama]/[nama]_varianX.jpg`, `validation/[suku]/[nama]/[nama]_varianX.jpg`, `testing/[suku]/[nama]/[nama]_varianX.jpg`.\n",
    "- Dependensi: Lihat `requirements.txt`.\n",
    "\n",
    "**Struktur Direktori**:\n",
    "```\n",
    "project/\n",
    "├── training.csv\n",
    "├── validation.csv\n",
    "├── testing.csv\n",
    "├── feature_extractor_siamese.h5\n",
    "├── ethnicity_model.h5\n",
    "├── label_encoder.pkl\n",
    "├── training/\n",
    "│   ├── Jawa/\n",
    "│   │   ├── John/\n",
    "│   │   │   ├── john_varian1.jpg\n",
    "│   │   │   ├── ...\n",
    "│   ├── Sunda/\n",
    "│   │   ├── ...\n",
    "├── validation/\n",
    "│   ├── Jawa/\n",
    "│   │   ├── ...\n",
    "│   ├── Sunda/\n",
    "│   │   ├── ...\n",
    "├── testing/\n",
    "│   ├── Jawa/\n",
    "│   │   ├── ...\n",
    "│   ├── Sunda/\n",
    "│   │   ├── ...\n",
    "├── face_similarity_ethnicity_detection.ipynb\n",
    "```\n",
    "\n",
    "**Catatan**:\n",
    "- Semua file (model, CSV, notebook) berada di direktori utama.\n",
    "- Output visualisasi (misalnya, `roc_curve.png`) akan disimpan di direktori utama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from mtcnn import MTCNN\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Konfigurasi\n",
    "IMG_SIZE = (255, 255)\n",
    "MODEL_PATH_SIAMESE = 'feature_extractor_siamese.h5'\n",
    "MODEL_PATH_ETHNICITY = 'ethnicity_model.h5'\n",
    "LABEL_ENCODER_PATH = 'label_encoder.pkl'\n",
    "\n",
    "# Inisialisasi MTCNN\n",
    "detector = MTCNN()\n",
    "\n",
    "# Muat model Siamese\n",
    "try:\n",
    "    feature_model = load_model(MODEL_PATH_SIAMESE)\n",
    "    feature_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    print(\"Model Siamese berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error memuat model Siamese: {e}\")\n",
    "    raise\n",
    "\n",
    "# Muat model deteksi suku/etnis dan LabelEncoder\n",
    "try:\n",
    "    ethnicity_model = load_model(MODEL_PATH_ETHNICITY)\n",
    "    with open(LABEL_ENCODER_PATH, 'rb') as f:\n",
    "        le = pickle.load(f)\n",
    "    print(\"Model deteksi suku/etnis dan LabelEncoder berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error memuat model deteksi suku/etnis: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi untuk memuat dan preprocess gambar (Face Similarity)\n",
    "def load_image(image_path):\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Gambar tidak ditemukan: {image_path}\")\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img_rgb, IMG_SIZE).astype('float32') / 255.0\n",
    "        return img\n",
    "    except Exception as e:\n",
    "        print(f\"Error memuat gambar {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fungsi untuk preprocess gambar dengan deteksi wajah (Deteksi Suku/Etnis)\n",
    "def preprocess_image(img_rgb, target_size=(255, 255)):\n",
    "    try:\n",
    "        faces = detector.detect_faces(img_rgb)\n",
    "        if len(faces) > 0:\n",
    "            x, y, w, h = faces[0]['box']\n",
    "            x, y = max(x, 0), max(y, 0)\n",
    "            face = img_rgb[y:y+h, x:x+w]\n",
    "            face = cv2.resize(face, target_size).astype('float32') / 255.0\n",
    "            return face\n",
    "        else:\n",
    "            raise ValueError(\"Wajah tidak terdeteksi.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocess gambar: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fungsi ekstraksi embedding (Face Similarity)\n",
    "def extract_embedding(face, model):\n",
    "    face = np.expand_dims(face, axis=0)\n",
    "    embedding = model.predict(face)\n",
    "    return embedding[0]\n",
    "\n",
    "# Fungsi Euclidean Distance (Face Similarity)\n",
    "def euclidean_distance_inference(emb1, emb2):\n",
    "    return np.sqrt(np.sum((emb1 - emb2) ** 2))\n",
    "\n",
    "# Konversi jarak ke skor kemiripan (Face Similarity)\n",
    "def distance_to_similarity(distance, max_distance=5.0):\n",
    "    similarity = max(0, 1 - (distance / max_distance))\n",
    "    return similarity\n",
    "\n",
    "# Fungsi visualisasi wajah dengan bounding box\n",
    "def draw_bbox(image_path):\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        faces = detector.detect_faces(img_rgb)\n",
    "        if faces:\n",
    "            for face in faces:\n",
    "                x, y, w, h = face['box']\n",
    "                cv2.rectangle(img_rgb, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        return img_rgb\n",
    "    except Exception as e:\n",
    "        print(f\"Error visualisasi {image_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validasi dataset\n",
    "def validate_dataset(csv_file):\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file, sep=';')\n",
    "        expected_columns = ['path', 'nama', 'suku', 'ekspresi', 'sudut', 'jarak', 'pencahayaan']\n",
    "        for col in expected_columns:\n",
    "            if col not in df.columns:\n",
    "                raise ValueError(f\"Kolom {col} tidak ditemukan di {csv_file}\")\n",
    "        \n",
    "        invalid_paths = []\n",
    "        for path in df['path']:\n",
    "            if not os.path.exists(path):\n",
    "                invalid_paths.append(path)\n",
    "        if invalid_paths:\n",
    "            print(f\"Path tidak valid di {csv_file}: {invalid_paths}\")\n",
    "        \n",
    "        counts = df['nama'].value_counts()\n",
    "        if any(counts < 2):\n",
    "            print(f\"Peringatan: Individu dengan <2 gambar di {csv_file}: {counts[counts < 2]}\")\n",
    "        \n",
    "        print(f\"{csv_file}: {len(df)} gambar, {len(counts)} individu, {len(df['suku'].unique())} suku\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error validasi {csv_file}: {e}\")\n",
    "        raise\n",
    "\n",
    "# Validasi semua CSV\n",
    "CSV_FILES = ['training.csv', 'validation.csv', 'testing.csv']\n",
    "dfs = {}\n",
    "for csv_file in CSV_FILES:\n",
    "    dfs[csv_file] = validate_dataset(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi Face Similarity\n",
    "def evaluate_face_similarity(df, model):\n",
    "    distances = []\n",
    "    labels = []\n",
    "    pairs_info = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        for j in range(i+1, len(df)):\n",
    "            img1_path = df['path'][i]\n",
    "            img2_path = df['path'][j]\n",
    "            face1 = load_image(img1_path)\n",
    "            face2 = load_image(img2_path)\n",
    "            if face1 is None or face2 is None:\n",
    "                continue\n",
    "            emb1 = extract_embedding(face1, model)\n",
    "            emb2 = extract_embedding(face2, model)\n",
    "            dist = euclidean_distance_inference(emb1, emb2)\n",
    "            distances.append(dist)\n",
    "            label = 1 if df['nama'][i] == df['nama'][j] else 0\n",
    "            labels.append(label)\n",
    "            pairs_info.append({\n",
    "                'image1': img1_path,\n",
    "                'image2': img2_path,\n",
    "                'distance': dist,\n",
    "                'label': label\n",
    "            })\n",
    "    \n",
    "    # Hitung ROC dan threshold\n",
    "    fpr, tpr, thresholds = roc_curve(labels, [-d for d in distances])\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    far_threshold = thresholds[np.where(fpr < 0.05)[0][-1]] if np.any(fpr < 0.05) else thresholds[0]\n",
    "    \n",
    "    # Hitung EER\n",
    "    eer_idx = np.argmin(np.abs(fpr - (1 - tpr)))\n",
    "    eer = fpr[eer_idx]\n",
    "    \n",
    "    # Visualisasi ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f'ROC (AUC = {auc_score:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.scatter(fpr[eer_idx], tpr[eer_idx], marker='o', color='red', label=f'EER = {eer:.4f}')\n",
    "    plt.title('ROC Curve Face Similarity')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend()\n",
    "    plt.savefig('roc_curve.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Visualisasi distribusi jarak\n",
    "    plt.figure()\n",
    "    sns.histplot([d for d, l in zip(distances, labels) if l == 1], label='Same Identity', color='blue', alpha=0.5)\n",
    "    sns.histplot([d for d, l in zip(distances, labels) if l == 0], label='Different Identity', color='red', alpha=0.5)\n",
    "    plt.legend()\n",
    "    plt.title('Distribusi Jarak Euclidean (Same vs Different Identity)')\n",
    "    plt.savefig('distance_distribution.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Hitung metrik\n",
    "    predictions = [1 if d < far_threshold else 0 for d in distances]\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='binary')\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    tar = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    far = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    frr = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    \n",
    "    # Visualisasi confusion matrix\n",
    "    plt.figure()\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix Face Similarity')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.savefig('confusion_matrix_facesimilarity.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Threshold dengan FAR < 0.05: {far_threshold:.4f}, AUC: {auc_score:.4f}\")\n",
    "    print(f\"EER: {eer:.4f}\")\n",
    "    print(f\"TAR: {tar:.4f}, FAR: {far:.4f}, FRR: {frr:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    return far_threshold, pairs_info\n",
    "\n",
    "# Jalankan evaluasi Face Similarity\n",
    "far_threshold, pairs_info = evaluate_face_similarity(dfs['testing.csv'], feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisasi t-SNE untuk Face Similarity\n",
    "def visualize_tsne(df, model):\n",
    "    embeddings = []\n",
    "    tsne_labels = []\n",
    "    for img_path, label in zip(df['path'], df['nama']):\n",
    "        face = load_image(img_path)\n",
    "        if face is None:\n",
    "            continue\n",
    "        emb = extract_embedding(face, model)\n",
    "        embeddings.append(emb)\n",
    "        tsne_labels.append(label)\n",
    "    \n",
    "    n_samples = len(embeddings)\n",
    "    if n_samples < 2:\n",
    "        print(\"Tidak cukup embedding untuk t-SNE.\")\n",
    "        return\n",
    "    \n",
    "    perplexity_value = min(5, n_samples - 1)\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity_value)\n",
    "    embeddings_2d = tsne.fit_transform(np.array(embeddings))\n",
    "    plt.figure()\n",
    "    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=pd.factorize(tsne_labels)[0])\n",
    "    plt.title('t-SNE Embedding Face Similarity')\n",
    "    plt.savefig('tsne_embedding.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Jalankan t-SNE\n",
    "visualize_tsne(dfs['testing.csv'], feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi Deteksi Suku/Etnis\n",
    "def evaluate_ethnicity(df, model, label_encoder):\n",
    "    images = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for img_path, suku in zip(df['path'], df['suku']):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        face = preprocess_image(img_rgb)\n",
    "        if face is None:\n",
    "            continue\n",
    "        images.append(face)\n",
    "        true_labels.append(suku)\n",
    "    \n",
    "    if not images:\n",
    "        print(\"Tidak ada gambar valid untuk evaluasi deteksi suku/etnis.\")\n",
    "        return\n",
    "    \n",
    "    images = np.array(images)\n",
    "    true_labels_enc = label_encoder.transform(true_labels)\n",
    "    pred = model.predict(images)\n",
    "    pred_classes = np.argmax(pred, axis=1)\n",
    "    \n",
    "    print(\"Evaluasi Deteksi Suku/Etnis (Testing):\")\n",
    "    print(classification_report(true_labels_enc, pred_classes, target_names=label_encoder.classes_))\n",
    "    \n",
    "    cm = confusion_matrix(true_labels_enc, pred_classes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix Deteksi Suku/Etnis')\n",
    "    plt.savefig('confusion_matrix_ethnicity.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Jalankan evaluasi deteksi suku/etnis\n",
    "evaluate_ethnicity(dfs['testing.csv'], ethnicity_model, le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh Inferensi\n",
    "def run_inference(img_path1, img_path2, feature_model, ethnicity_model, label_encoder, threshold):\n",
    "    # Face Similarity\n",
    "    face1 = load_image(img_path1)\n",
    "    face2 = load_image(img_path2)\n",
    "    if face1 is None or face2 is None:\n",
    "        print(\"Gagal memuat salah satu gambar.\")\n",
    "        return\n",
    "    emb1 = extract_embedding(face1, feature_model)\n",
    "    emb2 = extract_embedding(face2, feature_model)\n",
    "    dist = euclidean_distance_inference(emb1, emb2)\n",
    "    similarity_score = distance_to_similarity(dist)\n",
    "    is_match = dist < threshold\n",
    "    \n",
    "    # Deteksi Suku/Etnis\n",
    "    img1 = cv2.imread(img_path1)\n",
    "    img2 = cv2.imread(img_path2)\n",
    "    img1_rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "    img2_rgb = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "    face1_eth = preprocess_image(img1_rgb)\n",
    "    face2_eth = preprocess_image(img2_rgb)\n",
    "    suku_pred1 = None\n",
    "    suku_pred2 = None\n",
    "    prob_dict1 = None\n",
    "    prob_dict2 = None\n",
    "    if face1_eth is not None:\n",
    "        face1_input = np.expand_dims(face1_eth, axis=0)\n",
    "        pred1 = ethnicity_model.predict(face1_input)\n",
    "        suku_pred1 = label_encoder.inverse_transform([np.argmax(pred1)])[0]\n",
    "        prob_dict1 = {label_encoder.classes_[i]: pred1[0][i] for i in range(len(label_encoder.classes_))}\n",
    "    if face2_eth is not None:\n",
    "        face2_input = np.expand_dims(face2_eth, axis=0)\n",
    "        pred2 = ethnicity_model.predict(face2_input)\n",
    "        suku_pred2 = label_encoder.inverse_transform([np.argmax(pred2)])[0]\n",
    "        prob_dict2 = {label_encoder.classes_[i]: pred2[0][i] for i in range(len(label_encoder.classes_))}\n",
    "    \n",
    "    # Visualisasi\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    img1_viz = draw_bbox(img_path1)\n",
    "    if img1_viz is not None:\n",
    "        plt.imshow(img1_viz)\n",
    "        plt.title(f\"Suku: {suku_pred1 if suku_pred1 else 'Tidak Terdeteksi'}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    img2_viz = draw_bbox(img_path2)\n",
    "    if img2_viz is not None:\n",
    "        plt.imshow(img2_viz)\n",
    "        plt.title(f\"Suku: {suku_pred2 if suku_pred2 else 'Tidak Terdeteksi'}\")\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('inference_example.png')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Skor Kemiripan: {similarity_score:.4f} (Jarak Euclidean: {dist:.4f})\")\n",
    "    print(f\"Status: {'Match' if is_match else 'Tidak Match'}\")\n",
    "    if suku_pred1:\n",
    "        print(f\"Suku Gambar 1: {suku_pred1}\")\n",
    "        print(\"Probabilitas per Suku:\")\n",
    "        for suku, prob in prob_dict1.items():\n",
    "            print(f\"{suku}: {prob:.2%}\")\n",
    "    if suku_pred2:\n",
    "        print(f\"Suku Gambar 2: {suku_pred2}\")\n",
    "        print(\"Probabilitas per Suku:\")\n",
    "        for suku, prob in prob_dict2.items():\n",
    "            print(f\"{suku}: {prob:.2%}\")\n",
    "\n",
    "# Jalankan inferensi untuk dua gambar\n",
    "img_path1 = dfs['testing.csv']['path'].iloc[0]\n",
    "img_path2 = dfs['testing.csv']['path'].iloc[1]\n",
    "run_inference(img_path1, img_path2, feature_model, ethnicity_model, le, far_threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
